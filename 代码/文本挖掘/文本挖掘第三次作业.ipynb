{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81cd634e",
   "metadata": {},
   "source": [
    "# 2110010114 李佳琪"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3105e97",
   "metadata": {},
   "source": [
    "## 作业1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32c6718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7297d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分别利用： jieba.analyse.extract_tags, jieba.analyse.textrank函数，分别利用TF-IDF 算法、 TextRank 算法对下面两句话进行关键词提取：\n",
    "sentence1='''在克鲁伊夫时代，巴萨联赛中完成四连冠，后三个冠军都是在末轮逆袭获得的。在91//92赛季，巴萨末轮前落后皇马1分，结果皇马客场不敌特内里费使得巴萨逆转。一年之后，巴萨用几乎相同的方式逆袭，皇马还是末轮输给了特内里费。在93/94赛季中，巴萨末轮落后拉科1分。巴萨末轮5比2屠杀塞维利亚，拉科则0比0战平瓦伦西亚，巴萨最终在积分相同的情况下靠直接交锋时的战绩优势夺冠。神奇的是，拉科球员久基齐在终场前踢丢点球，这才有巴萨的逆袭。巴萨上一次压哨夺冠，发生在09/10赛季中。末轮前巴萨领先皇马1分，只要赢球就夺冠。末轮中巴萨4比0大胜巴拉多利德，皇马则与对手踢平。巴萨以99分的佳绩创下五大联赛积分记录，皇马则以96分成为了悲情的史上最强亚军。在48/49赛季中，巴萨末轮2比1拿下同城死敌西班牙人，以2分优势夺冠。52/53赛季，巴萨末轮3比0战胜毕巴，以2分优势力压瓦伦西亚夺冠。在59/60赛季，巴萨末轮5比0大胜萨拉戈萨。皇马巴萨积分相同，巴萨靠直接交锋时的战绩优势夺冠。'''\n",
    "sentence2='''巴萨上一次压哨夺冠，发生在09/10赛季中。末轮前巴萨领先皇马1分，只要赢球就将夺冠。末轮中巴萨4比0大胜巴拉多利德，皇马则与对手踢平。巴萨以99分的佳绩创下五大联赛积分纪录，皇马则以96分成为了悲情的史上最强亚军。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57b50d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "巴萨 1.2181461971020409\n",
      "末轮 0.7319245409938775\n",
      "皇马 0.5362676344\n",
      "夺冠 0.42225835063265305\n",
      "赛季 0.39762426810693874\n",
      "拉科 0.2471207792387755\n",
      "内里费 0.18912486601360545\n",
      "积分 0.1691336641957143\n",
      "逆袭 0.16264989799863944\n",
      "瓦伦西亚 0.16264989799863944\n",
      "优势 0.15362255099918368\n",
      "大胜 0.12660622859646256\n",
      "联赛 0.12398892393455782\n",
      "相同 0.12255595193938776\n",
      "战绩 0.12077275008340135\n",
      "交锋 0.11605496086870748\n",
      "四连冠 0.09456243300680273\n",
      "多利德 0.09456243300680273\n",
      "落后 0.09077944490340135\n",
      "克鲁伊夫 0.08708888002244898\n"
     ]
    }
   ],
   "source": [
    "# 利用 TF-IDF 算法进行关键词提取  \n",
    "keywords = jieba.analyse.extract_tags(sentence1, topK=20, withWeight=True, allowPOS=( ))  \n",
    "for item in keywords:  \n",
    "    print(item[0],item[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff6a86cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "末轮 2.3440720593921567\n",
      "皇马 1.5457125932705882\n",
      "内里费 0.5451246138039216\n",
      "优势 0.4427944117035294\n",
      "战绩 0.3481096914168627\n",
      "交锋 0.3345113577980392\n",
      "落后 0.26165840001568624\n",
      "基齐 0.23440720593921568\n",
      "压哨 0.23440720593921568\n",
      "赢球 0.23440720593921568\n",
      "力压 0.23440720593921568\n",
      "终场 0.2294794720509804\n",
      "敌特 0.2255447525333333\n",
      "战平 0.2255447525333333\n",
      "悲情 0.2158883508647059\n",
      "点球 0.21024752591372547\n",
      "佳绩 0.2028495998137255\n",
      "客场 0.19508693987039216\n",
      "球员 0.16847862656019608\n",
      "最强 0.15720304438215685\n"
     ]
    }
   ],
   "source": [
    "# 调整allowPOS（词性定义）参数值\n",
    "keywords = jieba.analyse.extract_tags(sentence1, topK=20, withWeight=True, allowPOS=('an'))  \n",
    "for item in keywords:  \n",
    "    print(item[0],item[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e4a007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "巴萨 1.0\n",
      "皇马 0.9647038899727614\n",
      "夺冠 0.8073721784610818\n",
      "末轮 0.6297349925484585\n",
      "联赛 0.600664118085894\n",
      "创下 0.47067655502117844\n",
      "纪录 0.4498468495044589\n",
      "压哨 0.41536179383993677\n",
      "领先 0.39941324147019747\n",
      "分成 0.39573128391530055\n",
      "佳绩 0.3283996770445692\n",
      "发生 0.2992699607664548\n",
      "对手 0.2849913237865385\n",
      "悲情 0.23769265698873052\n",
      "赢球 0.17827231017527065\n"
     ]
    }
   ],
   "source": [
    "# 利用 TextRank 算法进行关键词提取  \n",
    "keywords = jieba.analyse.textrank(sentence2, topK=20, withWeight=True)  \n",
    "for item in keywords:  \n",
    "    print(item[0],item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dc9ea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "皇马 1.0\n",
      "最强 0.6720104571545331\n",
      "悲情 0.6678134858080064\n",
      "领先 0.6600680680464339\n",
      "末轮 0.6543693577721991\n",
      "纪录 0.36473738131981354\n"
     ]
    }
   ],
   "source": [
    "# 调整allowPOS（词性定义）参数值\n",
    "keywords = jieba.analyse.textrank(sentence2, topK=20, withWeight=True,allowPOS=('an'))  \n",
    "for item in keywords:  \n",
    "    print(item[0],item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d2891",
   "metadata": {},
   "source": [
    "## 作业2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd2edd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "from gensim import corpora, models\n",
    "from jieba import analyse\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac3605ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停用词表加载方法\n",
    "def get_stopword_list():\n",
    "    # 停用词表存储路径，每一行为一个词，按行读取进行加载\n",
    "    # 进行编码转换确保匹配准确率\n",
    "    stop_word_path = 'D:\\\\大三上\\\\文本挖掘\\\\作业3\\\\作业2关键词提取数据\\\\stopword.txt'\n",
    "    stopword_list = [sw.replace('\\n', '') for sw in open(stop_word_path,encoding='utf-8').readlines()]\n",
    "    return stopword_list\n",
    "\n",
    "\n",
    "# 分词方法，调用结巴接口\n",
    "def seg_to_list(sentence, pos=False):\n",
    "    if not pos:\n",
    "        # 不进行词性标注的分词方法\n",
    "        seg_list = jieba.cut(sentence)\n",
    "    else:\n",
    "        # 进行词性标注的分词方法\n",
    "        seg_list = psg.cut(sentence)\n",
    "    return seg_list\n",
    "\n",
    "\n",
    "# 去除干扰词\n",
    "def word_filter(seg_list, pos=False):\n",
    "    stopword_list = get_stopword_list()\n",
    "    filter_list = []\n",
    "    # 根据POS参数选择是否词性过滤\n",
    "    ## 不进行词性过滤，则将词性都标记为n，表示全部保留\n",
    "    for seg in seg_list:\n",
    "        if not pos:\n",
    "            word = seg\n",
    "            flag = 'n'\n",
    "        else:\n",
    "            word = seg.word\n",
    "            flag = seg.flag\n",
    "        if not flag.startswith('n'):\n",
    "            continue\n",
    "        # 过滤停用词表中的词，以及长度为<2的词\n",
    "        if not word in stopword_list and len(word) > 1:\n",
    "            filter_list.append(word)\n",
    "\n",
    "    return filter_list\n",
    "\n",
    "\n",
    "# 数据加载，pos为是否词性标注的参数，corpus_path为数据集路径\n",
    "def load_data(pos=False, corpus_path='D:\\\\大三上\\\\文本挖掘\\\\作业3\\\\作业2关键词提取数据\\\\corpus.txt'):\n",
    "    # 调用上面方式对数据集进行处理，处理后的每条数据仅保留非干扰词\n",
    "    doc_list = []\n",
    "    for line in open(corpus_path, 'r',encoding='utf-8'):\n",
    "        content = line.strip()\n",
    "        seg_list = seg_to_list(content, pos)\n",
    "        filter_list = word_filter(seg_list, pos)\n",
    "        doc_list.append(filter_list)\n",
    "\n",
    "    return doc_list\n",
    "\n",
    "\n",
    "# idf值统计方法\n",
    "def train_idf(doc_list):\n",
    "    idf_dic = {}\n",
    "    # 总文档数\n",
    "    tt_count = len(doc_list)\n",
    "\n",
    "    # 每个词出现的文档数\n",
    "    for doc in doc_list:\n",
    "        for word in set(doc):\n",
    "            idf_dic[word] = idf_dic.get(word, 0.0) + 1.0\n",
    "\n",
    "    # 按公式转换为idf值，分母加1进行平滑处理\n",
    "    for k, v in idf_dic.items():\n",
    "        idf_dic[k] = math.log(tt_count / (1.0 + v))\n",
    "\n",
    "    # 对于没有在字典中的词，默认其仅在一个文档出现，得到默认idf值\n",
    "    default_idf = math.log(tt_count / (1.0))\n",
    "    return idf_dic, default_idf\n",
    "\n",
    "\n",
    "#  排序函数，用于topK关键词的按值排序\n",
    "def cmp(e1, e2):\n",
    "    import numpy as np\n",
    "    res = np.sign(e1[1] - e2[1])\n",
    "    if res != 0:\n",
    "        return res\n",
    "    else:\n",
    "        a = e1[0] + e2[0]\n",
    "        b = e2[0] + e1[0]\n",
    "        if a > b:\n",
    "            return 1\n",
    "        elif a == b:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c004a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF类\n",
    "class TfIdf(object):\n",
    "    # 四个参数分别是：训练好的idf字典，默认idf值，处理后的待提取文本，关键词数量\n",
    "    def __init__(self, idf_dic, default_idf, word_list, keyword_num):\n",
    "        self.word_list = word_list\n",
    "        self.idf_dic, self.default_idf = idf_dic, default_idf\n",
    "        self.tf_dic = self.get_tf_dic()\n",
    "        self.keyword_num = keyword_num\n",
    "\n",
    "    # 统计tf值\n",
    "    def get_tf_dic(self):\n",
    "        tf_dic = {}\n",
    "        for word in self.word_list:\n",
    "            tf_dic[word] = tf_dic.get(word, 0.0) + 1.0\n",
    "\n",
    "        tt_count = len(self.word_list)\n",
    "        for k, v in tf_dic.items():\n",
    "            tf_dic[k] = float(v) / tt_count\n",
    "\n",
    "        return tf_dic\n",
    "\n",
    "    # 按公式计算tf-idf\n",
    "    def get_tfidf(self):\n",
    "        tfidf_dic = {}\n",
    "        for word in self.word_list:\n",
    "            idf = self.idf_dic.get(word, self.default_idf)\n",
    "            tf = self.tf_dic.get(word, 0)\n",
    "\n",
    "            tfidf = tf * idf\n",
    "            tfidf_dic[word] = tfidf\n",
    "\n",
    "        tfidf_dic.items()\n",
    "        # 根据tf-idf排序，去排名前keyword_num的词作为关键词\n",
    "        for k, v in sorted(tfidf_dic.items(), key=functools.cmp_to_key(cmp), reverse=True)[:self.keyword_num]:\n",
    "            print(k + \"/ \", end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82381101",
   "metadata": {},
   "source": [
    "## 实验2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4d07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities  \n",
    "import jieba  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1a4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=['线程是程序执行时的最小单位，它是进程的一个执行流，\\是CPU调度和分派的基本单位，一个进程可以由很多个线程组成，\\线程间共享进程的所有资源，每个线程有自己的堆栈和局部变量。\\线程由CPU独立调度执行，在多CPU环境下就允许多个线程同时运行。\\同样多线程也可以实现并发操作，每个请求分配一个线程来处理。']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e4917d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 使用jieba进行分词  \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ss_seg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(jieba\u001b[38;5;241m.\u001b[39mcut(s)) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m ss]  \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 创建字典对象  \u001b[39;00m\n\u001b[0;32m      5\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m corpora\u001b[38;5;241m.\u001b[39mDictionary(ss_seg)  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'ss' is not defined"
     ]
    }
   ],
   "source": [
    "# 使用jieba进行分词  \n",
    "ss_seg = [list(jieba.cut(s)) for s in ss]  \n",
    "\n",
    "# 创建字典对象  \n",
    "dictionary = corpora.Dictionary(ss_seg)  \n",
    "  \n",
    "# 将字典对象转化为corpus对象  \n",
    "corpus = [dictionary.doc2bow(s) for s in ss_seg]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用TF-IDF模型  \n",
    "tfidf = models.TfidfModel(corpus)  \n",
    "corpus_tfidf = tfidf[corpus]  \n",
    "  \n",
    "# 使用LSI模型  \n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)  \n",
    "corpus_lsi = lsi[corpus_tfidf]  \n",
    "  \n",
    "# 使用LDA模型  \n",
    "lda = models.LdaModel(corpus_lsi, id2word=dictionary, num_topics=2, random_state=42)  \n",
    "corpus_lda = lda[corpus_lsi]  \n",
    "  \n",
    "# 打印关键词及其权重  \n",
    "for i in range(len(corpus)):  \n",
    "    print(f\"Topic for document {i+1}:\")  \n",
    "    print(dict(zip(dictionary.values(), [row[i] for row in corpus_lda[i]])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
